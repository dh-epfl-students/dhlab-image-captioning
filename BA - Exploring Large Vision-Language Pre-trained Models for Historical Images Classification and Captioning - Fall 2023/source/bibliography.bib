
@online{radford2021learning,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  year={2021},
  url={https://arxiv.org/abs/2103.00020},
}

@article{alayrac2022flamingo,
  title={Flamingo: A Visual Language Model for Few-Shot Learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022},
}

@misc{lucidrains2022flampytorch,
  title={Flamingo - Pytorch},
  author={Phil Wang},
  howpublished={\url{https://github.com/lucidrains/flamingo-pytorch}},
  year={2022},
}

@misc{mlfoundations2022openflamingo,
  title={Open Flamingo},
  author={Anas Awadalla},
  howpublished={\url{https://github.com/mlfoundations/open_flamingo}},
  year={2022},
}

@online{openai2022clip-repo,
  title={CLIP repository},
  organization={OpenAI},
  year={2022},
  url={https://github.com/openai/CLIP},
}

@online{huggingface2022clip,
  title={CLIP hugging face},
  organization={Hugging Face},
  year={2022},
  url={https://huggingface.co/docs/transformers/model_doc/clip},
}

@online{pinecone2022clip1,
  title={Zero-shot Image Classification with OpenAI's CLIP},
  organization={Pinecone},
  year={2022},
  url={https://www.pinecone.io/learn/series/image-search/zero-shot-image-classification-clip/},
}

@online{pinecone2022clip2,
  title={Multi-modal ML with OpenAI's CLIP},
  organization={Pinecone},
  year={2022},
  url={https://www.pinecone.io/learn/series/image-search/clip/},
}

@article{bisk2020experience,
  title={Experience Grounds Language},
  author={Yonatan Bisk and Ari Holtzman and Jesse Thomason and Jacob Andreas and Yoshua Bengio and Joyce Chai and Mirella Lapata and Angeliki Lazaridou and Jonathan May and Aleksandr Nisnevich and Nicolas Pinto and Joseph P. Turian},
  journal={CoRR},
  volume={abs/2004.10151},
  year={2020},
  url={https://arxiv.org/abs/2004.10151},
}

@article{maniparambil2023clip-gpt4,
  title={Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts},
  author={Mayug Maniparambil and Chris Vorster and Derek Molloy and Noel Murphy and Kevin McGuinness and Noel E. O'Connor},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022},
  url={https://arxiv.org/abs/2307.11661},
}

@article{dhlab2022impresso,
  title={Historical Newspaper Image Classification},
  author={Pauline Isabela Conti},
  organization={EPFL DHLAB},
  year={2022},
  url={https://github.com/impresso/impresso-image-classification/tree/pauline},
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{fu2023mme,
  title={Mme: A comprehensive evaluation benchmark for multimodal large language models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Yang, Jinrui and Zheng, Xiawu and Li, Ke and Sun, Xing and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@article{deng2022rlprompt,
  title={Rlprompt: Optimizing discrete text prompts with reinforcement learning},
  author={Deng, Mingkai and Wang, Jianyu and Hsieh, Cheng-Ping and Wang, Yihan and Guo, Han and Shu, Tianmin and Song, Meng and Xing, Eric P and Hu, Zhiting},
  journal={arXiv preprint arXiv:2205.12548},
  year={2022}
}

@article{fan2023improving,
  title={Improving CLIP Training with Language Rewrites},
  author={Fan, Lijie and Krishnan, Dilip and Isola, Phillip and Katabi, Dina and Tian, Yonglong},
  journal={arXiv preprint arXiv:2305.20088},
  year={2023}
}


@online{deepmind2022flamingo,
  title={YouTube: Enhancing the user experience},
  organization={Google DeepMind},
  year={2022},
  url={https://www.deepmind.com/blog/working-together-with-youtube?utm_source=linkedin&utm_medium=social&utm_campaign=YouTubeShorts},
}
